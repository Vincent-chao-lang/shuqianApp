#
# vision_adapter.py
# å¤šæ¨¡å‹è§†è§‰åˆ†æé€‚é…å™¨
#

from abc import ABC, abstractmethod
from typing import List, Dict, Any
from enum import Enum
import httpx
from loguru import logger

from app.models.schemas import (
    ImageAnalysisResult,
    LayoutInfo,
    ColorScheme,
    DesignColor,
    Typography,
    StyleAttributes,
    MoodType,
    LayoutType,
    DecorativeElements,
)
from app.core.config import settings


class VisionModel(str, Enum):
    """æ”¯æŒçš„è§†è§‰æ¨¡å‹"""
    GLM = "glm"
    QWEN = "qwen"
    CLAUDE = "claude"


class VisionAnalyzerAdapter(ABC):
    """è§†è§‰åˆ†æå™¨é€‚é…å™¨åŸºç±»"""

    def __init__(self, api_key: str, model: str):
        self.api_key = api_key
        self.model = model
        self.timeout = 60.0

    @abstractmethod
    async def analyze_images(self, image_paths: List[str]) -> ImageAnalysisResult:
        """
        åˆ†æå›¾ç‰‡ï¼ˆå­ç±»å¿…é¡»å®ç°ï¼‰

        Args:
            image_paths: å›¾ç‰‡è·¯å¾„åˆ—è¡¨

        Returns:
            ImageAnalysisResult: åˆ†æç»“æœ
        """
        pass

    def _encode_image(self, image_path: str) -> str:
        """å°†å›¾ç‰‡ç¼–ç ä¸ºbase64"""
        import base64
        with open(image_path, "rb") as f:
            image_data = f.read()
        return base64.b64encode(image_data).decode("utf-8")

    async def _make_request(
        self,
        url: str,
        headers: Dict[str, str],
        payload: Dict[str, Any]
    ) -> Dict[str, Any]:
        """å‘é€HTTPè¯·æ±‚ï¼ˆé€šç”¨æ–¹æ³•ï¼‰"""
        async with httpx.AsyncClient(timeout=self.timeout) as client:
            response = await client.post(url, headers=headers, json=payload)
            response.raise_for_status()
            return response.json()


class GLMAnalyzer(VisionAnalyzerAdapter):
    """GLM-4V è§†è§‰åˆ†æå™¨ï¼ˆä½¿ç”¨å®˜æ–¹SDKï¼‰"""

    def __init__(self, api_key: str):
        super().__init__(api_key, "glm-4v-flash")
        try:
            from zhipuai import ZhipuAI
            self.client = ZhipuAI(api_key=api_key)
            logger.info("âœ… [GLM] Official SDK initialized")
        except ImportError:
            logger.error("âŒ [GLM] zhipuai package not found, using fallback")
            self.client = None

    async def analyze_images(self, image_paths: List[str]) -> ImageAnalysisResult:
        """ä½¿ç”¨GLM-4Våˆ†æå›¾ç‰‡"""
        logger.info(f"ğŸ¤– [GLM] Analyzing {len(image_paths)} images with {self.model}")

        if not self.client:
            logger.error("âŒ [GLM] SDK not available, using mock")
            return self._get_mock_result()

        try:
            # å‡†å¤‡æ¶ˆæ¯å†…å®¹ (ä½¿ç”¨GLM SDKçš„å¤šæ¨¡æ€æ ¼å¼)
            prompt = self._get_analysis_prompt()

            # æ„å»ºå†…å®¹åˆ—è¡¨
            content_list = [
                {
                    "type": "text",
                    "text": prompt
                }
            ]

            # æ·»åŠ å›¾ç‰‡
            for img_path in image_paths:
                base64_image = self._encode_image(img_path)
                content_list.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{base64_image}"
                    }
                })

            messages = [{
                "role": "user",
                "content": content_list
            }]

            logger.info(f"ğŸŒ [GLM] Calling API with {len(image_paths)} images")

            # è°ƒç”¨GLM API
            response = self.client.chat.completions.create(
                model="glm-4v",
                messages=messages,
                temperature=0.7,
                max_tokens=2000
            )

            # æå–åˆ†æç»“æœ
            result_content = response.choices[0].message.content
            logger.info(f"âœ… [GLM] API call successful")
            logger.info(f"ğŸ“ [GLM] Response length: {len(result_content)}")
            logger.info(f"ğŸ“ [GLM] Response preview: {result_content[:500]}")

            return self._parse_result(result_content)

        except Exception as e:
            logger.error(f"âŒ [GLM] Error: {str(e)}")
            logger.exception(e)
            # è¿”å›mockç»“æœ
            return self._get_mock_result()

    def _get_analysis_prompt(self) -> str:
        """è·å–GLMåˆ†ææç¤ºè¯"""
        return """è¯·åˆ†æè¿™å¼ å›¾ç‰‡å¹¶è¿”å›JSONæ ¼å¼çš„ç»“æœã€‚

è¦æ±‚æ ¼å¼ï¼š
{
  "layout": "left-right",
  "colors": ["#é¢œè‰²1", "#é¢œè‰²2"],
  "mood": "æ¸©æš–æ²»æ„ˆ",
  "complexity": 3
}

æ³¨æ„ï¼š
- layoutåªèƒ½é€‰: left-right, top-bottom, center-focused, mosaic-grid, full-bleed-image
- moodåªèƒ½é€‰: æ¸©æš–æ²»æ„ˆ, æ¸…æ–°è‡ªç„¶, ä¸“ä¸šç®€çº¦, æ´»æ³¼å¯çˆ±, ä¼˜é›…å¤å¤, ç°ä»£æ—¶å°š, è‰ºæœ¯æ–‡è‰º
- colorsç”¨HEXæ ¼å¼å¦‚#FFFFFF
- complexityæ˜¯1-5çš„æ•°å­—

**åªè¿”å›JSONï¼Œä¸è¦ä»»ä½•å…¶ä»–æ–‡å­—**ã€‚"""

    def _parse_result(self, content: str) -> ImageAnalysisResult:
        """è§£æGLMè¿”å›çš„ç»“æœ"""
        import json

        logger.info(f"ğŸ” [GLM] Parsing response content...")

        # æå–previewï¼ˆåŸå§‹å†…å®¹çš„å‰500å­—ç¬¦ï¼‰
        preview_text = content[:500] if len(content) > 500 else content

        # å°è¯•ä»contentä¸­æå–JSON
        try:
            json_start = content.find("{")
            json_end = content.rfind("}") + 1
            if json_start >= 0 and json_end > json_start:
                json_str = content[json_start:json_end]
                logger.info(f"ğŸ” [GLM] Extracted JSON: {json_str}")
                data = json.loads(json_str)
                logger.info(f"âœ… [GLM] JSON parsed successfully")
                return self._convert_to_result(data, preview=preview_text)
        except Exception as e:
            logger.warning(f"âš ï¸ [GLM] Failed to parse JSON: {e}")
            logger.debug(f"âš ï¸ [GLM] Content was: {content}")

        # è§£æå¤±è´¥ï¼Œè¿”å›mockç»“æœ
        logger.info("âš ï¸ [GLM] Using mock result due to parse failure")
        return self._get_mock_result(preview=preview_text)

    def _convert_to_result(self, data: Dict, preview: str = None) -> ImageAnalysisResult:
        """å°†GLMè¿”å›çš„æ•°æ®è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼"""
        # æå–æ•°æ®æˆ–ä½¿ç”¨é»˜è®¤å€¼
        layout_str = data.get("layout", "left-right")
        colors_list = data.get("colors", ["#F5E6D3", "#8B7355", "#D4A574", "#333333"])
        mood_str = data.get("mood", "æ¸©æš–æ²»æ„ˆ")
        complexity = data.get("complexity", 3)

        # æ˜ å°„å¸ƒå±€ç±»å‹
        layout_map = {
            "left-right": LayoutType.HORIZONTAL,
            "top-bottom": LayoutType.VERTICAL,
            "center-focused": LayoutType.CENTERED,
            "mosaic-grid": LayoutType.MOSAIC,
            "full-bleed-image": LayoutType.FULL_BLEED
        }
        layout_type = layout_map.get(layout_str, LayoutType.HORIZONTAL)

        # æ˜ å°„æƒ…ç»ªç±»å‹
        mood_map = {
            "æ¸©æš–æ²»æ„ˆ": MoodType.WARM,
            "æ¸…æ–°è‡ªç„¶": MoodType.FRESH,
            "ä¸“ä¸šç®€çº¦": MoodType.PROFESSIONAL,
            "æ´»æ³¼å¯çˆ±": MoodType.PLAYFUL,
            "ä¼˜é›…å¤å¤": MoodType.ELEGANT,
            "ç°ä»£æ—¶å°š": MoodType.MODERN,
            "è‰ºæœ¯æ–‡è‰º": MoodType.ARTISTIC
        }
        mood_type = mood_map.get(mood_str, MoodType.WARM)

        # æ„å»ºé¢œè‰²åˆ—è¡¨
        def get_color(hex_val, name):
            return DesignColor(hex=hex_val.upper() if hex_val.startswith("#") else f"#{hex_val}", name=name)

        colors = ColorScheme(
            primary=[get_color(colors_list[0], "ä¸»è‰²")] if len(colors_list) > 0 else [],
            secondary=[get_color(colors_list[1], "è¾…è‰²")] if len(colors_list) > 1 else [],
            accent=[get_color(colors_list[2], "ç‚¹ç¼€è‰²")] if len(colors_list) > 2 else [],
            neutral=[get_color(colors_list[3], "ä¸­æ€§è‰²")] if len(colors_list) > 3 else [],
            palette_name=f"{mood_str}é…è‰²",
            mood=mood_str,
            harmony="å’Œè°æ­é…"
        )

        logger.info(f"âœ… [GLM] Converted result: layout={layout_str}, mood={mood_str}, complexity={complexity}")

        return ImageAnalysisResult(
            layout=LayoutInfo(
                type=layout_type,
                confidence=0.9,
                description=f"{layout_str}å¸ƒå±€"
            ),
            colors=colors,
            typography=Typography(
                primary_font="ä¼˜é›…è¡¬çº¿ä½“",
                body_font="ç®€æ´æ— è¡¬çº¿ä½“",
                font_pairs=["å®‹ä½“ + é»‘ä½“"],
                text_color="#333333"
            ),
            style_attributes=StyleAttributes(
                keywords=[mood_str],
                mood=mood_type,
                complexity=complexity,
                aesthetic_tags=[]
            ),
            decorative_elements=DecorativeElements(
                has_border=True,
                has_pattern=False,
                has_icon=False,
                suggested_elements=[]
            ),
            suggestions=[f"åŸºäº{mood_str}é£æ ¼çš„è®¾è®¡å»ºè®®"],
            preview=preview,
            raw_analysis=str(data)
        )

    def _get_mock_result(self, preview: str = None) -> ImageAnalysisResult:
        """è·å–mockç»“æœï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        logger.info("ğŸ­ [GLM] Returning mock result")
        return self._convert_to_result({}, preview=preview)


class QwenAnalyzer(VisionAnalyzerAdapter):
    """Qwen-VL è§†è§‰åˆ†æå™¨"""

    def __init__(self, api_key: str):
        super().__init__(api_key, "qwen-vl-plus")
        self.api_url = "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"

    async def analyze_images(self, image_paths: List[str]) -> ImageAnalysisResult:
        """ä½¿ç”¨Qwen-VLåˆ†æå›¾ç‰‡"""
        logger.info(f"ğŸ¤– [Qwen] Analyzing {len(image_paths)} images with {self.model}")

        # å‡†å¤‡æ¶ˆæ¯
        messages = [{
            "role": "user",
            "content": []
        }]

        # æ·»åŠ æç¤ºè¯
        prompt = self._get_analysis_prompt()
        messages[0]["content"].append({"type": "text", "text": prompt})

        # æ·»åŠ å›¾ç‰‡
        for img_path in image_paths:
            base64_image = self._encode_image(img_path)
            messages[0]["content"].append({
                "type": "image_url",
                "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}
            })

        # æ„å»ºè¯·æ±‚
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        payload = {
            "model": self.model,
            "messages": messages,
            "temperature": 0.7
        }

        try:
            logger.info(f"ğŸŒ [Qwen] Sending request to {self.api_url}")
            result = await self._make_request(self.api_url, headers, payload)

            content = result.get("choices", [{}])[0].get("message", {}).get("content", "")
            logger.info(f"âœ… [Qwen] Analysis completed")

            return self._parse_result(content)

        except Exception as e:
            logger.error(f"âŒ [Qwen] Error: {str(e)}")
            return self._get_mock_result()

    def _get_analysis_prompt(self) -> str:
        """è·å–Qwenåˆ†ææç¤ºè¯"""
        return """è¯·åˆ†æè¿™å¼ ä¹¦ç­¾è®¾è®¡å›¾ç‰‡ï¼Œæå–ï¼š
1. å¸ƒå±€ç±»å‹ (left-right/top-bottom/center-focused/mosaic-grid/full-bleed-image)
2. ä¸»è‰²è°ƒå’Œé…è‰²æ–¹æ¡ˆ (HEXæ ¼å¼)
3. é£æ ¼æ°›å›´ (æ¸©æš–æ²»æ„ˆ/æ¸…æ–°è‡ªç„¶/ä¸“ä¸šç®€çº¦/æ´»æ³¼å¯çˆ±/ä¼˜é›…å¤å¤/ç°ä»£æ—¶å°š/è‰ºæœ¯æ–‡è‰º)
4. å¤æ‚åº¦ (1-5)

è¿”å›JSONæ ¼å¼ç»“æœã€‚"""

    def _parse_result(self, content: str) -> ImageAnalysisResult:
        """è§£æQwenç»“æœ"""
        import json
        try:
            json_start = content.find("{")
            json_end = content.rfind("}") + 1
            if json_start >= 0:
                data = json.loads(content[json_start:json_end])
                return self._convert_to_result(data)
        except:
            pass
        return self._get_mock_result()

    def _convert_to_result(self, data: Dict) -> ImageAnalysisResult:
        """è½¬æ¢ç»“æœæ ¼å¼"""
        return ImageAnalysisResult(
            layout=LayoutInfo(
                type=LayoutType.HORIZONTAL,
                confidence=0.9,
                description="å·¦å³åˆ†æ å¸ƒå±€"
            ),
            colors=ColorScheme(
                primary=[DesignColor(hex="#F5E6D3", name="ç±³è‰²")],
                secondary=[DesignColor(hex="#8B7355", name="æ£•è¤")],
                accent=[DesignColor(hex="#D4A574", name="é‡‘æ£•")],
                neutral=[DesignColor(hex="#333333", name="æ·±ç°")],
                palette_name="æ¸©æš–ç±³è‰²ç³»",
                mood="æ¸©æš–ã€èˆ’é€‚",
                harmony="é‚»è¿‘è‰²æ­é…"
            ),
            typography=Typography(
                primary_font="ä¼˜é›…è¡¬çº¿ä½“",
                body_font="ç®€æ´æ— è¡¬çº¿ä½“",
                font_pairs=["å®‹ä½“ + é»‘ä½“"],
                text_color="#333333"
            ),
            style_attributes=StyleAttributes(
                keywords=["ç®€çº¦", "ä¼˜é›…"],
                mood=MoodType.WARM,
                complexity=3,
                aesthetic_tags=["ç•™ç™½", "å±…ä¸­"]
            ),
            decorative_elements=DecorativeElements(
                has_border=True,
                has_pattern=False,
                has_icon=True,
                suggested_elements=["è¾¹æ¡†", "è£…é¥°"]
            ),
            suggestions=["å»ºè®®æ·»åŠ ç²¾ç¾è¾¹æ¡†"],
            raw_analysis=str(data)
        )

    def _get_mock_result(self) -> ImageAnalysisResult:
        """è·å–mockç»“æœ"""
        logger.info("ğŸ­ [Qwen] Returning mock result")
        return self._convert_to_result({})


class ClaudeAnalyzerAdapter(VisionAnalyzerAdapter):
    """Claude Vision è§†è§‰åˆ†æå™¨ï¼ˆé€‚é…å™¨åŒ…è£…ï¼‰"""

    def __init__(self, api_key: str):
        super().__init__(api_key, "claude-3-5-sonnet-20241022")
        self.api_url = "https://api.anthropic.com/v1/messages"
        # é‡ç”¨ç°æœ‰çš„Claudeåˆ†æå™¨
        from app.services.claude_analyzer import ClaudeAnalyzer
        self.claude = ClaudeAnalyzer()

    async def analyze_images(self, image_paths: List[str]) -> ImageAnalysisResult:
        """ä½¿ç”¨Claudeåˆ†æå›¾ç‰‡"""
        logger.info(f"ğŸ¤– [Claude] Analyzing {len(image_paths)} images")
        return await self.claude.analyze_images(image_paths)


class VisionAnalyzerFactory:
    """è§†è§‰åˆ†æå™¨å·¥å‚"""

    _analyzers: Dict[VisionModel, VisionAnalyzerAdapter] = {}

    @classmethod
    def get_analyzer(cls, model: VisionModel = VisionModel.GLM) -> VisionAnalyzerAdapter:
        """è·å–æŒ‡å®šæ¨¡å‹çš„åˆ†æå™¨"""
        if model in cls._analyzers:
            return cls._analyzers[model]

        # æ ¹æ®æ¨¡å‹ç±»å‹åˆ›å»ºåˆ†æå™¨
        if model == VisionModel.GLM:
            api_key = settings.GLM_API_KEY
            analyzer = GLMAnalyzer(api_key)
        elif model == VisionModel.QWEN:
            api_key = settings.QWEN_API_KEY
            analyzer = QwenAnalyzer(api_key)
        elif model == VisionModel.CLAUDE:
            api_key = settings.ANTHROPIC_API_KEY
            analyzer = ClaudeAnalyzerAdapter(api_key)
        else:
            raise ValueError(f"Unsupported model: {model}")

        cls._analyzers[model] = analyzer
        logger.info(f"âœ… [Factory] Created {model.value} analyzer")
        return analyzer

    @classmethod
    def get_default_analyzer(cls) -> VisionAnalyzerAdapter:
        """è·å–é»˜è®¤åˆ†æå™¨ï¼ˆGLMï¼‰"""
        return cls.get_analyzer(VisionModel.GLM)


# å…¨å±€å®ä¾‹
vision_analyzer = VisionAnalyzerFactory.get_default_analyzer()
